import boto3
import csv

def lambda_handler(event, context):
    # Set up the AWS access configuration

    # Create a boto3 client to access Lambda
    client = boto3.client('lambda')
    
    # Get a list of all regions
    regions = [r['RegionName'] for r in boto3.client('ec2').describe_regions()['Regions']]
    
    print(regions)
    
    # Create a list to store the function information
    functions_info = []
    
    # Iterate through each region
    for region in regions:
        # Create a boto3 client for the specific region
        region_client = boto3.client('lambda', region_name=region)
        
        # Get a list of all functions in the region
        functions = region_client.list_functions()['Functions']
        
        # Iterate through each function
        for function in functions:
            # Get the function information
            function_info = region_client.get_function_configuration(FunctionName=function['FunctionName'])
            
            # Store the function information in the list
            functions_info.append({
                'FunctionName': function_info['FunctionName'],
                'Region': region,
                'Runtime': function_info['Runtime'],
                'MemorySize': function_info['MemorySize'],
                'ProvisionedConcurrency': function_info.get('ProvisionedConcurrency', 'Not Set')
            })
    print(functions_info)
    
    # Write the contents of the CSV file to S3
    s3 = boto3.client('s3')
    csv_content = csv.StringIO()
    fieldnames = ['FunctionName', 'Region', 'Runtime', 'MemorySize', 'ProvisionedConcurrency']
    writer = csv.DictWriter(csv_content, fieldnames=fieldnames)
    writer.writeheader()
    for function_info in functions_info:
        writer.writerow(function_info)
    s3.put_object(Bucket='hellokeke', Key='lambda_functions_new.csv', Body=csv_content.getvalue())
    
    return 'CSV file written to S3'
